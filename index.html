<!doctype html>
<html lang="en" class="no-js">

<head>
    <meta charset="utf-8">
    <title>Yitao Hu - Homepage</title>
    <meta property="og:locale" content="en">
    <meta property="og:site_name" content="Yitao Hu">
    <meta property="og:title" content="Yitao Hu">
    <meta property="og:description" content="About me">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- <meta http-equiv="Content-Security-Policy" content="default-src 'self'"> -->
    <script>
        document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
    </script>
    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/main.css">
    <meta http-equiv="cleartype" content="on">

    <head>
        <base target="_blank">
    </head>
    <link rel="manifest" href="images/site.webmanifest">
    <meta name="msapplication-TileColor" content="#000000">
    <meta name="msapplication-TileImage" content="images/mstile-144x144.png?v=M44lzPylqQ">
    <meta name="msapplication-config" content="images/browserconfig.xml?v=M44lzPylqQ">
    <meta name="theme-color" content="#ffffff">
    <link rel="stylesheet" href="assets/css/academicons.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <script>
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();

                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
            });
        });
    </script>
    </script>
</head>

<body>
    <div id="main" role="main">
        <!---------------------------- INFO ---------------------------->
        <div class="author">
            <div class="sidebar sticky">
                <div itemscope itemtype="http://schema.org/Person" class="profile_box">
                    <div class="top3">
                        <div class="author__avatar">
                            <img src="images/yitao.png" class="author__avatar" alt="Yitao Hu">
                        </div>
                        <div class="author__content">
                            <h3 class="author__name"> Yitao Hu (胡一涛)</h3>
                        </div>

                        <div class="professor2"><span><i class="myhidden">
                                    <!-- <a href="mailto:yitao@tju.edu.cn"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i></a> -->
                                </i>Professor <i class="hidden-s"><a href="mailto:yitao@tju.edu.cn"><i
                                            class="fas fa-fw fa-envelope" aria-hidden="true"></i></a></i></span>
                        </div>
                    </div>
                    <div class="hidden-s1">
                        <a href="./zh.html">中文主页</a>
                    </div>
                    <div class="author__urls-wrapper">
                        <!-- <button class="btn btn--inverse">More Info & Contact</button> -->
                        <!-- class="author__urls social-icons" -->
                        <ul class="my_author_ul">
                            <li style="margin-top: 5px;"><a href="https://www.tju.edu.cn/english/index.htm"><i
                                        class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Tianjin University <span
                                        class="break-on-mobile"><br>&nbsp;&nbsp;&nbsp;&nbsp;</span>(天津大学)</a>
                            </li>
                            <li><a href="https://cic.tju.edu.cn/english/home.htm"><i class="fa fa-fw fa-map-marker"
                                        aria-hidden="true"></i> Department of
                                    <span class="break-on-mobile"><br>&nbsp;&nbsp;&nbsp;&nbsp;</span>
                                    Computer
                                    Science</a>
                            </li>
                            <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Office: 55-B122</li>
                            <li class="someone"><a href="mailto:yitao@tju.edu.cn"><i class="fas fa-fw fa-envelope"
                                        aria-hidden="true"></i>
                                    yitao@tju.edu.cn</a></li>
                            <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Tianjin, China</li>
                            <li class="jump"><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> <a
                                    href="./zh.html" target="_self">中文主页</a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>


        <!---------------------------- INTRO ---------------------------->
        <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
            <meta itemprop="headline" content="Yitao Hu">
            <div class="page__inner-wrap">
                <section class="page__content" itemprop="text">
                    <p><span class="anchor" id="about-me"></span></p>
                    <h1><strong>About me</strong></h1>
                    <p>I am a professor in <a href="https://cic.tju.edu.cn/english/home.htm">Department of Computer Science</a> at <a href="https://www.tju.edu.cn/english/index.htm">Tianjin University</a> and a member of <a href="http://www.tjutanklab.com/">TANK Lab</a>, led by <a href="https://cic.tju.edu.cn/faculty/likeqiu/index.html">Prof.Keqiu Li</a>. I received my Ph.D. degree from <a href="https://nsl.usc.edu/">Networked Systems Lab</a> at <a href="https://www.usc.edu/">University of Southern California</a>, advised by <a href="https://govindan.usc.edu/">Prof.Ramesh Govidan</a>. I obtained my B.S. degree at <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a>, advised by <a href="https://www.cs.sjtu.edu.cn/~wang-xb/">Prof. Xinbing Wang</a>.
                    </p>
                    <p>My research interests include large language model (LLM) systems, retrieval augmented generation (RAG) and AI for Science (AI4Science). My recent work delves into developing inference systems capable of deploying LLM and AI4Science models in large-scale cloud clusters, aiming for peak performance, efficiency and scalability through innovative techniques such as computational acceleration, parallel optimization, and resource orchestration. In collaboration with research institutions like IBM Watson, Samsung Research and Microsoft Research, I have published tens of papers at the leading conferences/journals, including SoCC, Ubicomp, INFOCOM, IWQoS, ASPLOS, SIGCOMM, TPDS and TC. My research has been funed by NSFC, etc. I have received honors such as U35 Outstanding Talent Award from Tianjin University and <a href="https://flashserve.org/images/best_paper_socc2024.jpg">Best Paper Award</a> from ACM SoCC'24.
                      <!-- Chun-Tsung Scholar from Shanghai Jiao Tong University and Qiming Scholar from Tianjin University. -->
                      <!-- deep neural network (DNN) systems, performance analysis and optimization, parallel and distributed computing -->
                    </p>
                    <p>I have developed <strong><a href="https://twen.ai/">Twen.ai</a></strong>, an university Q&A large language model. Empowered by RAG techniques, Twen addresses daily questions from students and faculties in areas such as daily life, scholarship selection, further studies, etc. Twen is officially released in April 2024, and serves thousands of requests each day since then. Recently, I am actively developing <strong><a href="https://student.tju.edu.cn/ai">Xiaotian</a></strong>, the official AI mentor that is <a href="https://mp.weixin.qq.com/s/06SXRGDh-Zx2hYIKYBn7bw">available to all students at Tianjin University since September 2025</a>.
                    </p>
                    <div class="lookingfor">
                        <p><strong>
                                I am looking for self-motivated students interested in building systems for large language model and AI4Science. Feel free to <a href="mailto:yitao@tju.edu.cn">drop me an email</a> if you want to join us!
                            </strong>
                        </p>
                    </div>


                    <!---------------------------- RESEARCH ---------------------------->

                    <h1 id="-news">Research</h1>
                    <p>
                        My research is aiming to build inference systems capable of <i class="myresearch">deploying LLM and AI4Science models in large-scale cloud clusters </i>with peak performance, efficiency and scalability.
                    </p>
                    <ul>
                        <li>
                            <h3>Large Language Model System</h3>

                            <ul class="myul">
                                <li>
                                    <span class="li-text">
                                        <i class="myh3">Seving Classic LLM</i>: Serving LLM applications brings new challenges due to their huge memory consumption and unpredictable output length. We designed novel LLM inference systems (qLLM, tgLLM) to minimize job completion time across LLM requests and to maximize model throughput and resource utilization. We also built various inference systems (InferRAG, InferMM) to manage computation resources under scenarios such as RAG and multi-modal.
                                    </span>
                                    <span class="li-img" id="no1">
                                        <img src="images/LLM_offline.png" alt=".." width="500">
                                    </span>
                                </li>
                            </ul>

                            <ul class="myul">
                                <li>
                                    <span class="li-text">
                                        <i class="myh3">Serving Specialized LLM</i>: Recent innovations in LLM architecture also bring new challenges. We designed specialized inference systems (SuperSpec, ParaMoE) to optimize the inference pipeline for speculative decoding and mixture of expert. Besides, we also investigated interesting topics such as lookahead decoding, LoRA serving, kv-cache optimization, etc.
                                    </span>
                                    <span class="li-img">
                                        <img src="images/LLM_MoE_load.png" alt=".." width="500">
                                    </span>
                                </li>
                            </ul>
                        </li>
                        <li>
                            <h3>Deep Neural Network System</h3>

                            <ul class="myul">
                                <li>
                                    <span class="li-text">
                                        <i class="myh3">Latency Sensitive Inference</i>: To guarantee good user experiences, DNN-based applications are usually associated with a latency objective. We designed various model orchestration systems (Harpagon, DeepLat, TopInfer) to minimize the serving cost under latency objective via techniques such as dynamic batching, request dispatching and configuration decoupling. We also built various resource scaling systems (SLOpt, DeepChain) to maximize system goodput under bursty workload via techniques such as AoT compilation and model pre-warmup.
                                    </span>
                                    <span class="li-img">
                                        <img src="images/DNN_SLOpt.png" alt=".." width="500">
                                    </span>
                                </li>
                            </ul>

                            <ul class="myul">
                                <li>
                                    <span class="li-text">
                                        <i class="myh3">Complex Scenario</i>: Given the use cases, DNN-based applications face various deployment requirements. We have designed multi-stage inference systems (<a href="https://dl.acm.org/doi/abs/10.1145/3472883.3486993">Scrooge</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3450268.3453521">Rim</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3274808.3274813">Olympian</a>)</i> to manage DNN models in edge/cloud GPU clusters via techniques such as model co-location and model promotion. We also built specialized systems (<a href="https://dl.acm.org/doi/abs/10.1145/2971648.2971674">ALPS</a>, <a href="https://ieeexplore.ieee.org/abstract/document/10188703">HRL</a>)</i> to handle complex scenario such as multi-modal input and heterogeneous hardware.
                                    </span>
                                    <span class="li-img" id="111">
                                        <img src="images/DNN_InferNet_2.png" alt=".." width="500">
                                    </span>
                            </ul>
                    </ul>


                    <!---------------------------- PUBLICATIONS ---------------------------->

                    <h1 id="-selected-publications">Selected Publications</h1>
                    <ul>
                        <li>[ASPLOS 26] PAT: Accelerating LLM Decoding via Prefix-Aware Attention with Resource Efficient Multi-Tile Kernel (CCF-A) [<a href="https://arxiv.org/abs/2511.22333">paper</a>][<a href="https://github.com/flashserve/PAT">code</a>][<a href="https://github.com/sugartom/sugartom.github.io/tree/master/slides/ASPLOS26_PAT_Prefix_Aware_Attention.pdf">slides</a>]
                        </li>
                        <li>[TPDS 26] Accelerating ML Inference via Opportunistic Pre-Loading on Serverless Clusters (CCF-A) [paper]
                        </li>
                        <li>[Preprint 26] RAGPulse: An Open-Source RAG Workload Trace to Optimize RAG Serving Systems [<a href="https://arxiv.org/abs/2511.12979">paper</a>][<a href="https://github.com/flashserve/RAGPulse">code</a>][<a href="https://huggingface.co/datasets/flashserve/RAGPulse">huggingface</a>]
                        </li>
                        <li>[Preprint 26] KernelBand: Boosting LLM-based Kernel Optimization with a Hierarchical and Hardware-aware Multi-armed Bandit [<a href="https://arxiv.org/abs/2511.18868">paper</a>]
                        </li>
                        <li>[Preprint 26] ServerlessLoRA: Minimizing Latency and Cost in Serverless Inference for LoRA-Based LLMs [<a href="https://arxiv.org/abs/2505.14468">paper</a>]
                        </li>
                        <li>[TC 25] TightLLM: Maximizing Throughput for LLM Inference via Adaptive Offloading Policy (CCF-A) [<a href="https://ieeexplore.ieee.org/document/10949701">paper</a>]
                        </li>
                        <li>[TC 25] SLOpt: Serving Real-Time Inference Pipeline with Strict Latency Constraint (CCF-A) [<a href="https://ieeexplore.ieee.org/document/10836842">paper</a>]
                        </li>
                        <li>[INFOCOM 25] Harpagon: Minimizing DNN Serving Cost via Efficient Dispatching, Scheduling and Splitting (CCF-A) [<a href="https://ieeexplore.ieee.org/abstract/document/11044536">paper</a>]
                        </li>
                        <li>[INFOCOM 25] Lark: A Buffer-aware Building Block for Programmable Packet Scheduling in Datacenters (CCF-A) [<a href="https://ieeexplore.ieee.org/abstract/document/11044448">paper</a>]
                        </li>
                        <li>[SoCC 24] Pre-Warming is Not Enough: Accelerating Serverless Inference With Opportunistic Pre-Loading (CCF-B, <i class="bestpaper">Best Paper Award</i>) [<a href="https://dl.acm.org/doi/10.1145/3698038.3698509">paper</a>]
                        </li>
                        <li>[SIGCOMM 24] PPT: A Pragmatic Transport for Datacenters (CCF-A) [<a href="https://dl.acm.org/doi/10.1145/3651890.3672235">paper</a>]
                        </li>
                        <li>[ASPLOS 24] FUYAO: DPU-enabled Direct Data Transfer for Serverless Computing (CCF-A) [<a href="https://dl.acm.org/doi/10.1145/3620666.3651327">paper</a>]
                        </li>
                        <li>[IWQoS 23] High-throughput Sampling, Communicating and Training for Reinforcement Learning Systems (CCF-B) [<a href="https://ieeexplore.ieee.org/abstract/document/10188703">paper</a>]
                        </li>
                        <li>[TPDS 23] Accelerating Data Delivery of Latency-Sensitive Applications in Container Overlay Network (CCF-A) [<a href="https://ieeexplore.ieee.org/abstract/document/10198904">paper</a>]
                        </li>
                        <li>[SoCC 21] Scrooge: A Cost-Effective Deep Learning Inference System (CCF-B) [<a href="https://dl.acm.org/doi/abs/10.1145/3472883.3486993">paper</a>]
                        </li>
                        <li>[IoTDI 21] Rim: Offloading Inference to the Edge [<a href="https://dl.acm.org/doi/abs/10.1145/3450268.3453521">paper</a>]
                        </li>
                        <li>[Middleware 18] Olympian: Scheduling GPU Usage in a Deep Neural Network Model Serving System (CCF-B) [<a href="https://dl.acm.org/doi/abs/10.1145/3274808.3274813">paper</a>]
                        </li>
                        <li>[Ubicomp 16] ALPS: Accurate Landmark Positioning at City Scales (CCF-A) [<a href="https://dl.acm.org/doi/abs/10.1145/2971648.2971674">paper</a>]
                        </li>
                        <li>[INFOCOM 14] Critical Sensing Range for Mobile Heterogeneous Camera Sensor Networks (CCF-A) [<a href="https://ieeexplore.ieee.org/abstract/document/6848026">paper</a>]
                        </li>
                    </ul>


                    <!---------------------------- AWARDS ---------------------------->

                    <h1 id="-honors-and-awards">Honors and Awards</h1>
                    <ul>
                        <li>Outstanding Undergraduate Thesis Advisor, Tianjin University, 2025</li>
                        <li>U35 Outstanding Talent Award, Tianjin University, 2025</li>
                        <li>Best Paper Award, ACM SoCC, 2024</li>
                        <li>Outstanding Young Academic Talent Award, Tianjin University, 2024</li>
                        <li>Qiming Scholar, Tianjin University, 2023</li>
                        <li>Chun-Tsung Scholar (<a href="https://mp.weixin.qq.com/s/rNHzswm6M2jHpe6u88JruQ">1st at SJTU</a>), Shanghai Jiao Tong University, 2014</li>
                        <li>Valedictorian at SEIEE, Shanghai Jiao Tong University, 2014</li>
                    </ul>


                    <!---------------------------- SERVICES ---------------------------->

                    <div class="services">
                        <h1 id="-teaching">Teaching</h1>
                        <ul>
                            <li>Computer Systems, TJU, 23Spring, 24Spring, 25Spring</li>
                            <li>Design and Analysis of Algorithms, TJU, 23Fall, 25Spring</li>
                            <li>Introduction to Internetworking, USC, 16Spring</li>
                        </ul>
                    </div>


                    <!---------------------------- STUDENTS ---------------------------->

                    <div class="students">
                        <h1 id="-students">Students</h1>
                        PhD Students
                        <ul>
                            <li>Zhixin Zhao (2022 - Now)<sup>1</sup></li>
                            <li>Guotao Yang (2023 - Now)<sup>1</a></sup></li>
                            <li>Liang Zheng (2024 - Now)<sup>2</sup></li>
                        </ul>
                        Master Students
                        <ul>
                            <li>Ziqi Gong (2023 - Now)</li>
                            <li>Chen Shen (2023 - Now)</li>
                            <li>Jingyuan Xiao (2024 - Now)</li>
                            <li>Jinjun Yi (2024 - Now)</li>
                            <li>Zhengchao Wang (2024 - Now)<sup>2</sup></li>
                            <li>Tao Wang (2024 - Now)<sup>1</sup></li>
                            <li>Yongfeng Wang (2025 - Now)</li>
                            <li>Shi Chen (2025 - Now)</li>
                            <li>Kaining Hui (2025 - Now)</li>
                            <li>Siwei He (2025 - Now)</li>
                            <li>Jianing Ye (2025 - Now)</li>
                            <li>Bowen Shi (2025 - Now)</li>
                        </ul>
                        Undergraduate Students
                        <ul>
                            <li>Rui Guo (2024 - Now)</li>
                            <li>Hao Chen (2024 - Now)</li>
                            <li>Xinpei Wang (2025 - Now)</li>
                            <li>Ke Yan (2025 - Now)</li>
                            <li>Mingxi Zhao (2025 - Now)</li>
                            <li>Zhuxuan Chang (2025 - Now)</li>
                            <li>Yongzhi Shi (2025 - Now)</li>
                            <li>Fujiang Liu (2025 - Now)</li>
                            <li>Jiazheng Yu (2025 - Now)</li>
                            <li>Fengkai Zhu (2025 - Now)</li>
                            <li>Longfei Yin (2025 - Now)</li>
                            <li>Haopeng Li (2025 - Now)</li>
                            <li>Jingyang Pan (2025 - Now)</li>
                            <li>Xinqiang Yu (2025 - Now)</li>
                            <li>Weibo Xu (2025 - Now)</li>
                            <li>Tengyi Wang (2025 - Now)</li>
                            <li>Zhike Guo (2025 - Now)</li>
                            <li>Yipeng Wu (2025 - Now)</li>
                        </ul>

                    </div>

                    <!---------------------------- ALUMNI ---------------------------->

                    <div class="alumni">
                        <h1 id="-alumni">Alumni</h1>
                        Master Students
                        <ul>
                            <li>Jiaheng Gao (MS, <a href="https://flashserve.org/images/graduation_2025_03.jpg">2025</a>) &rarr; Tencent</li>
                            <li>Linxuan Li (MS, <a href="https://flashserve.org/images/graduation_2025_03.jpg">2025</a>) &rarr; Alibaba</li>
                            <li>Yingqin Chen (MS, <a href="https://flashserve.org/images/graduation_2024.jpg">2024</a>)<sup>2</sup> &rarr; China Mobile</li>
                        </ul>
                        Undergraduate Students
                        <ul>
                            <li>Mingfang Ji (BS, 2026) &rarr; PhD at Fudan</li>
                            <li>Zhenyi Zhong (BS, 2026; <a href="https://mp.weixin.qq.com/s/ToUQ6hRC2r_GitimZTSRBg">Student Science Award</a>, which is highest student honor at TJU) &rarr; PhD at SJTU</li>
                            <li>Ke Wang (BS, 2026) &rarr; PhD at SJTU</li>
                            <li>Junhui Zheng (BS, 2026) &rarr; PhD at SJTU</li>
                            <li>Kai Zeng (BS, 2026) &rarr; MS at PKU</li>
                            <li>Yang Cheng (BS, 2026) &rarr; MS at Tsinghua</li>
                            <li>Haoran Zhao (BS, 2026) &rarr; MS at Fudan</li>
                            <li>Wenxin Zhu (BS, <a href="https://flashserve.org/images/graduation_2025_06.jpg">2025</a>) &rarr; MS at Tsinghua</li>
                            <li>Yongfeng Wang (BS, <a href="https://flashserve.org/images/graduation_2025_06.jpg">2025</a>) &rarr; MS at TJU</li>
                            <li>Shi Chen (BS, <a href="https://flashserve.org/images/graduation_2025_06.jpg">2025</a>) &rarr; MS at TJU</li>
                            <li>Rongwei Wang (BS, <a href="https://flashserve.org/images/graduation_2024.jpg">2024</a>) &rarr; MS at Tsinghua</li>
                            <li>Jingyuan Xiao (BS, <a href="https://flashserve.org/images/graduation_2024.jpg">2024</a>) &rarr; MS at TJU</li>
                            <li>Ziqi Gong (BS, 2023) &rarr; MS at TJU</li>
                            <li>Guotao Yang (BS, 2023) &rarr; MS+PhD at TJU</li>
                        </ul>
                            <hr>
                            <li class="co">1. co-advised with <a
                                    href="https://cic.tju.edu.cn/faculty/wyqu/index.html">Prof. Wenyu Qu</a>
                            </li>
                            <li class="co">2. co-advised with <a
                                    href="https://cic.tju.edu.cn/faculty/likeqiu/index.html">Prof. Keqiu Li</a>
                            </li>
                    </div>

                </section>
            </div>
        </article>
    </div>
</body>

</html>